{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read me\n",
    "\n",
    "Je n'ai encore jamais tenté de faire tourner le script sur la totalité de lightnovelworld.com (j'étais allée assez loin dans la collecte sans rencontrer d'erreur mais il est possible qu'il en traîne encore).\n",
    "\n",
    "Je n'ai pas encore réussi à inclure les langues d'origine (principalement chinois, japonais et coréen) des livres dans la collecte de données. Je me pencherai à nouveau dessus quand j'en aurai le temps et actualiserai le fichier si j'y parviens.\n",
    "\n",
    "Il est nécessaire que l'appareil qui lance le script ait installé Chrome.\n",
    "\n",
    "Le nombre de pages présentant les livres du site (avant-dernière cellule, ligne 2) a été rentré manuellement, il était de 86 la dernière fois que j'y suis allée (fin juin 2024). Il pourrait être à actualiser s'il venait à changer.\n",
    "\n",
    "En raison des coupures de réseau, j'ai dû ajouter des conditions afin que la collecte ne stoppe pas. L'avantage est qu'à présent elle saute les livres qui n'ont pas pu être collectés (et les précise à la fin de la collecte) ; l'inconvénient est que le script met du temps à s'arrêter si on veut l'interrompre..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du fichier CSV\n",
    "def initialize_csv(file_name):\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            'Novel Title', 'Alternative Title', 'Author Name', 'Rank', 'Rating', \n",
    "            'Chapters', 'Views', 'Bookmarked', 'Status', 'Categories', 'Summary', \n",
    "            'Tags', 'Last Updated', 'First Chapter Release'\n",
    "        ])\n",
    "\n",
    "# Ecriture des données dans le fichier CSV\n",
    "def write_to_csv(file_name, data):\n",
    "    with open(file_name, mode='a', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecte des liens pour une page du site\n",
    "def get_book_links(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    page_content = driver.page_source\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    h4_tags = soup.find_all('h4', class_='novel-title text2row')\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for h4 in h4_tags:\n",
    "        a_tag = h4.find('a')\n",
    "        if a_tag and 'href' in a_tag.attrs:\n",
    "            links.append(a_tag['href'])\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecte des informations (sans les dates) sur un livre\n",
    "def get_book_info(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    page_content = driver.page_source\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    novel_info = soup.find('div', class_='novel-info')\n",
    "\n",
    "    if novel_info:\n",
    "\n",
    "        title_tag = novel_info.find('h1', class_='novel-title text2row')\n",
    "        title = title_tag.text.strip() if title_tag else 'N/A'\n",
    "\n",
    "        alt_title_tag = novel_info.find('h2', class_='alternative-title text1row')\n",
    "        alt_title = alt_title_tag.text.strip() if alt_title_tag else 'N/A'\n",
    "\n",
    "        author_tag = novel_info.find('a', class_='property-item')\n",
    "        author = author_tag.text.strip() if author_tag else 'N/A'\n",
    "\n",
    "        rank_tag = novel_info.find('div', class_='rank')\n",
    "        rank = rank_tag.find('strong').text.strip().replace('RANK ', '') if rank_tag and rank_tag.find('strong') else 'N/A'\n",
    "\n",
    "        rating_tag = novel_info.find('div', class_='rating-star')\n",
    "        rating = rating_tag.find('strong').text.strip() if rating_tag and rating_tag.find('strong') else 'N/A'\n",
    "\n",
    "        chapters_tag = novel_info.find('div', class_='header-stats')\n",
    "        chapters = chapters_tag.find('strong').text.strip().replace('<i class=\"icon-book-open\">::before</i>','') if chapters_tag and chapters_tag.find('strong') else 'N/A'\n",
    "\n",
    "        views_tag = novel_info.find('i', class_='icon-book-open')\n",
    "        views = views_tag.find_next('strong').text.strip().replace('\"', '') if views_tag and views_tag.find_next('strong') else 'N/A'\n",
    "\n",
    "        bookmarks_tag = novel_info.find('i', class_='icon-eye')\n",
    "        bookmarks = bookmarks_tag.find_next('strong').text.strip().replace('\"', '') if bookmarks_tag and bookmarks_tag.find_next('strong') else 'N/A'\n",
    "\n",
    "        status_tag = novel_info.find('i', class_='icon-bookmark')\n",
    "        status = status_tag.find_next('strong').text.strip().replace('\"', '') if status_tag and status_tag.find_next('strong') else 'N/A'\n",
    "\n",
    "        categories_list = []\n",
    "        categories_tag = novel_info.find('div', class_='categories')\n",
    "        if categories_tag:\n",
    "            category_links = categories_tag.find_all('a', class_='property-item')\n",
    "            for link in category_links:\n",
    "                categories_list.append(link.text.strip())\n",
    "        categories = ', '.join(categories_list) if categories_list else 'N/A'\n",
    "\n",
    "        summary_tag = soup.find('div', class_='summary')\n",
    "        summary = summary_tag.find('p').text.strip().replace('\"', '') if summary_tag and summary_tag.find('p') else 'N/A'\n",
    "\n",
    "        tags_list = []\n",
    "        tags_section = soup.find('div', class_='tags')\n",
    "        if tags_section:\n",
    "            tag_links = tags_section.find_all('a')\n",
    "            for link in tag_links:\n",
    "                tag_text = link.text.strip()\n",
    "                if tag_text != 'Show More':\n",
    "                    tags_list.append(tag_text)\n",
    "        tags = ', '.join(tags_list) if tags_list else 'N/A'\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            'Novel Title': title,\n",
    "            'Alternative Title': alt_title,\n",
    "            'Author Name': author,\n",
    "            'Rank': rank,\n",
    "            'Rating': rating,\n",
    "            'Chapters': chapters,\n",
    "            'Views': views,\n",
    "            'Bookmarked': bookmarks,\n",
    "            'Status': status,\n",
    "            'Categories': categories,\n",
    "            'Summary': summary,\n",
    "            'Tags': tags\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecte des dates pour un livre\n",
    "def get_book_dates(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    page_content = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    novel_info = soup.find('article', id='chapter-list-page')\n",
    "\n",
    "    updated = 'N/A'\n",
    "    release = 'N/A'\n",
    "\n",
    "    if novel_info:\n",
    "\n",
    "        updated_tag = novel_info.find('time', {'datetime': True})\n",
    "        if updated_tag:\n",
    "            updated = updated_tag['datetime']\n",
    "        \n",
    "        chapter_list_section = novel_info.find('section', id='chpagedlist')\n",
    "        \n",
    "        if chapter_list_section:\n",
    "            release_tag = chapter_list_section.find('time', {'datetime': True})\n",
    "            if release_tag:\n",
    "                release = release_tag['datetime']\n",
    "\n",
    "    return {\n",
    "        'Last Updated': updated,\n",
    "        'First Chapter Release': release\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom du fichier CSV\n",
    "base_filename = 'lightnovelworld'\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "csv_file = f\"{base_filename}_{current_date}.csv\"\n",
    "\n",
    "# Initialisation du fichier CSV\n",
    "initialize_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://www.lightnovelworld.com/browse/genre-all-25060123/order-popular/status-all'\n",
    "total_pages = 86 # A mettre à jour\n",
    "liant = '?page='\n",
    "\n",
    "# Liste pour stocker les numéros de passage des œuvres manquantes\n",
    "failed_attempts = []\n",
    "\n",
    "# Boucle pour itérer sur les numéros de page\n",
    "for page_num in range(1, total_pages + 1):\n",
    "    page_url = f\"{url_base}{liant}{page_num}\"\n",
    "    book_links = get_book_links(page_url)\n",
    "    \n",
    "    for index, link in enumerate(book_links, start=1):\n",
    "        try:\n",
    "            true_link = f\"https://www.lightnovelworld.com{link}\"\n",
    "            chapters_link = f\"https://www.lightnovelworld.com{link}/chapters\"\n",
    "            info = get_book_info(true_link)\n",
    "            dates = get_book_dates(chapters_link)\n",
    "\n",
    "            # Combiner les informations des livres et les dates\n",
    "            book_data = [\n",
    "                info['Novel Title'], info['Alternative Title'], info['Author Name'], \n",
    "                info['Rank'], info['Rating'], info['Chapters'], info['Views'], \n",
    "                info['Bookmarked'], info['Status'], info['Categories'], \n",
    "                info['Summary'], info['Tags'], dates['Last Updated'], \n",
    "                dates['First Chapter Release']\n",
    "            ]\n",
    "            \n",
    "            # Écrire les données dans le fichier CSV\n",
    "            write_to_csv(csv_file, book_data)\n",
    "            print(info)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with {true_link}: {e}\")\n",
    "            failed_attempts.append((page_num, index))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les numéros de passage des œuvres manquantes\n",
    "if failed_attempts:\n",
    "    print(\"\\nList of failed attempts (Page number, Link index):\")\n",
    "    for attempt in failed_attempts:\n",
    "        print(attempt)\n",
    "\n",
    "print('Data collect complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
